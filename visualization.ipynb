{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e395e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import cv2\n",
    "import open3d as o3d\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe3dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = 'PSMNet'\n",
    "# MODEL_PATH = 'PSMNet\\\\pretrained\\\\pretrained_sceneflow_new.tar'\n",
    "MODEL_NAME = 'RAFT-Stereo'\n",
    "MODEL_PATH = \"RAFT-Stereo/models/raftstereo-realtime.pth\"\n",
    "TEST_LEFT_IMG = \"G:\\\\My Drive\\\\Dataset\\\\20250619-xi-testing\\\\stereo\\\\L\\\\pose\\\\L00000016.tif\"\n",
    "TEST_RIGHT_IMG = \"G:\\\\My Drive\\\\Dataset\\\\20250619-xi-testing\\\\stereo\\\\R\\\\pose\\\\R00000016.tif\"\n",
    "\n",
    "# stereo_params is from SystemCalibration (npz file with K/D/R/T/R_L/R_R/P_L/P_R/Q)\n",
    "stereo_params = np.load('stereo_params.npz')\n",
    "IMG_SIZE = (894, 714)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c934f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = utils.load_model(MODEL_NAME, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2673bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Undistortion and Rectification Remapping\n",
    "K_L = stereo_params['K_L']\n",
    "D_L = stereo_params['D_L']\n",
    "K_R = stereo_params['K_R']\n",
    "D_R = stereo_params['D_R']\n",
    "R_L = stereo_params['R_L']\n",
    "R_R = stereo_params['R_R']\n",
    "P_L = stereo_params['P_L']\n",
    "P_R = stereo_params['P_R']\n",
    "Q = stereo_params['Q']\n",
    "\n",
    "mapL1, mapL2 = cv2.initUndistortRectifyMap(K_L, D_L, R_L, P_L, IMG_SIZE, cv2.CV_16SC2)\n",
    "mapR1, mapR2 = cv2.initUndistortRectifyMap(K_R, D_R, R_R, P_R, IMG_SIZE, cv2.CV_16SC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2c181d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------- Main runner ------------------------------------\n",
    "def run_visualizer(\n",
    "    mode: str,                                    # \"images\" | \"video\"\n",
    "    stereo_params: dict,                          # dict with K/D/R/T/R_L/R_R/P_L/P_R/Q\n",
    "    left_map1, left_map2, right_map1, right_map2, # rectification remap\n",
    "    model_name: str = \"\",                         # \"RAFT-Stereo\" | \"PSMNet\"\n",
    "    display_mode: str = \"overlay\",                # \"overlay\" | \"points_only\" | \"both\"\n",
    "    radius: int = 2,\n",
    "    alpha: float = 0.6,\n",
    "    tint_strength: float = 0.7,\n",
    "    blur: int = 9,\n",
    "    # images mode\n",
    "    left_img_path: str = \"\",\n",
    "    right_img_path: str = \"\",\n",
    "    # video mode\n",
    "    left_src: str = \"\",\n",
    "    right_src: str = \"\",\n",
    "    target_size: tuple = None,            # (w, h) or None\n",
    "):\n",
    "    \"\"\"\n",
    "    Visualize uL / uR either from a pair of images or from two live video streams.\n",
    "\n",
    "    Dependencies in utils.py:\n",
    "      - load_model(model_name, model_weights)             (already called outside)\n",
    "      - compute_disparity(model_name, model, left, right, left_map1,left_map2,right_map1,right_map2)\n",
    "      - generate_pointcloud(model_name, disp, left, left_map1,left_map2, Q)\n",
    "      - transform_pointcloud(pcd_or_points, stereo_params)\n",
    "      - overlay_pointcloud_image(img_bgr, u, radius, alpha, tint_strength, blur, mode)\n",
    "\n",
    "    Notes:\n",
    "      - For \"video\", left_src and right_src should be two independent inputs (camera indices or stream URIs).\n",
    "      - Rectification maps are assumed to match IMG_SIZE. If your frames differ, we resize to IMG_SIZE first.\n",
    "    \"\"\"\n",
    "    # -------------------------- images mode --------------------------------------\n",
    "    if mode == \"images\":\n",
    "        imgL = cv2.imread(left_img_path,  cv2.IMREAD_COLOR)\n",
    "        imgR = cv2.imread(right_img_path, cv2.IMREAD_COLOR)\n",
    "        assert imgL is not None and imgR is not None, \"Failed to read input images.\"\n",
    "\n",
    "        # Disparity (use utils to keep the pipeline consistent)\n",
    "        disp = utils.compute_disparity(\n",
    "            model_name, model,\n",
    "            left_img_path, right_img_path,\n",
    "            left_map1, left_map2, right_map1, right_map2\n",
    "        )\n",
    "\n",
    "        # Point cloud (rectified-left frame)\n",
    "        pcd = utils.generate_pointcloud(\n",
    "            model_name, disp, left_img_path, left_map1, left_map2, stereo_params['Q']\n",
    "        )\n",
    "\n",
    "        # Transform to original coordinate system\n",
    "        pcd_rect_L, pcd_rect_R = utils.pcd_to_rectified_images(pcd, stereo_params, (894, 714))\n",
    "        pcd_rect_L = cv2.flip(pcd_rect_L, 1)\n",
    "        pcd_rect_R = cv2.flip(pcd_rect_R, 1)\n",
    "        uL = utils.inverse_remap_rectified_to_original(pcd_rect_L, stereo_params, camera=\"left\")\n",
    "        uR = utils.inverse_remap_rectified_to_original(pcd_rect_R, stereo_params, camera=\"right\")\n",
    "        \n",
    "        # Visualize using utils.overlay_pointcloud_image\n",
    "        def _viz_one(win, img, u):\n",
    "            vis = utils.overlay_pointcloud_image(\n",
    "                img, u,\n",
    "                radius=radius, alpha=alpha,\n",
    "                tint_strength=tint_strength, blur=blur,\n",
    "                mode=display_mode\n",
    "            )\n",
    "            if isinstance(vis, tuple):  # \"both\"\n",
    "                cv2.imshow(f\"{win} overlay\", vis[0])\n",
    "                cv2.imshow(f\"{win} points\",  vis[1])\n",
    "            else:\n",
    "                cv2.imshow(win, vis)\n",
    "\n",
    "        _viz_one(\"uL\", imgL, uL)\n",
    "        _viz_one(\"uR\", imgR, uR)\n",
    "\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        return\n",
    "    \n",
    "    # -------------------------- video mode ---------------------------------------\n",
    "    elif mode == \"video\":\n",
    "        # Open left/right video sources\n",
    "        capL = cv2.VideoCapture(left_src)\n",
    "        capR = cv2.VideoCapture(right_src)\n",
    "        assert capL.isOpened() and capR.isOpened(), \"Failed to open left/right video sources.\"\n",
    "\n",
    "        # Read first frames\n",
    "        okL, frameL0 = capL.read()\n",
    "        okR, frameR0 = capR.read()\n",
    "        assert okL and okR,  \"Failed to read the first frame from left/right sources.\"\n",
    "\n",
    "        # Decide a working size; maps were built for IMG_SIZE, so weâ€™ll default to that\n",
    "        if target_size is None:\n",
    "            H0, W0 = frameL0.shape[:2]\n",
    "            size_wh = (W0, H0)\n",
    "        else:\n",
    "            size_wh = target_size\n",
    "\n",
    "        while True:\n",
    "            t0 = time.time()\n",
    "\n",
    "            # Better sync: grab then retrieve\n",
    "            capL.grab(); capR.grab()\n",
    "            okL, frameL = capL.retrieve()\n",
    "            okR, frameR = capR.retrieve()\n",
    "            if not (okL and okR):\n",
    "                break\n",
    "\n",
    "            # Disparity on frames (compute_disparity accepts ndarray frames)\n",
    "            disp = utils.compute_disparity_frames(\n",
    "                model_name, \n",
    "                model,\n",
    "                left = frameL, right = frameR,              # pass ndarray frames\n",
    "                left_map1 = left_map1, left_map2 = left_map2,\n",
    "                right_map1 = right_map1, right_map2 = right_map2)\n",
    "            \n",
    "            # Point cloud using the left frame (function will remap internally)            \n",
    "            pcd = utils.generate_pointcloud_frames(\n",
    "                model_name, \n",
    "                disp, \n",
    "                left = frameL,                             # pass ndarray left frame\n",
    "                left_map1 = left_map1, left_map2 = left_map2, \n",
    "                Q = Q)\n",
    "            \n",
    "            # Transform to original coordinate system\n",
    "            pcd_rect_L, pcd_rect_R = utils.pcd_to_rectified_images(pcd, stereo_params, (894, 714))\n",
    "            pcd_rect_L = cv2.flip(pcd_rect_L, 1)\n",
    "            pcd_rect_R = cv2.flip(pcd_rect_R, 1)\n",
    "            uL = utils.inverse_remap_rectified_to_original(pcd_rect_L, stereo_params, camera=\"left\")\n",
    "            uR = utils.inverse_remap_rectified_to_original(pcd_rect_R, stereo_params, camera=\"right\")\n",
    "\n",
    "            # Visualize on the raw frames\n",
    "            def _viz(win, img, u):\n",
    "                vis = utils.overlay_pointcloud_image(\n",
    "                    img, u,\n",
    "                    radius=radius, alpha=alpha,\n",
    "                    tint_strength=tint_strength, blur=blur,\n",
    "                    mode=display_mode\n",
    "                )\n",
    "                if isinstance(vis, tuple):  # \"both\"\n",
    "                    cv2.imshow(f\"{win} overlay\", vis[0])\n",
    "                    cv2.imshow(f\"{win} points\",  vis[1])\n",
    "                else:\n",
    "                    cv2.imshow(win, vis)\n",
    "            \n",
    "            _viz(\"uL\", frameL, uL)\n",
    "            _viz(\"uR\", frameR, uR)\n",
    "\n",
    "            # FPS display\n",
    "            fps = 1.0 / max(time.time() - t0, 1e-6)\n",
    "            try:\n",
    "                cv2.setWindowTitle(\"uL\", f\"uL  ({fps:.1f} FPS)\")\n",
    "                cv2.setWindowTitle(\"uR\", f\"uR  ({fps:.1f} FPS)\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            k = cv2.waitKey(1) & 0xFF\n",
    "            if k in (27, ord('q')):  # ESC / q\n",
    "                break\n",
    "\n",
    "        capL.release(); capR.release()\n",
    "        cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d94a5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------- Example usage ------------------------------------\n",
    "run_visualizer(\n",
    "    mode=\"images\",\n",
    "    stereo_params=stereo_params,\n",
    "    left_map1=mapL1, left_map2=mapL2, right_map1=mapR1, right_map2=mapR2,\n",
    "    model_name=MODEL_NAME,\n",
    "    left_img_path=TEST_LEFT_IMG,\n",
    "    right_img_path=TEST_RIGHT_IMG,\n",
    "    display_mode=\"both\",    # \"overlay\" | \"points_only\" | \"both\"\n",
    "    radius=2, alpha=0.6, tint_strength=0.7, blur=11\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6611af2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------------------------- Example usage ------------------------------------\n",
    "# run_visualizer(\n",
    "#     mode=\"video\",\n",
    "#     stereo_params=stereo_params,\n",
    "#     left_map1=mapL1, left_map2=mapL2, right_map1=mapR1, right_map2=mapR2,\n",
    "#     model_name=MODEL_NAME,\n",
    "#     left_src=0, right_src=1,                 # two independent live streams\n",
    "#     display_mode=\"overlay\",                  # \"overlay\" | \"points_only\" | \"both\"\n",
    "#     radius=2, alpha=0.6, tint_strength=0.7, blur=11,\n",
    "#     target_size=IMG_SIZE                     # or (W,H) to enforce a working size\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "raftstereo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
